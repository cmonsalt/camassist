import { createClient } from '@supabase/supabase-js';

const supabase = process.env.SUPABASE_URL ? createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_KEY
) : null;

export default async function handler(req, res) {
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  const {
    token,
    username,
    message,
    tip = 0,
    context = [],
    isPM = false,
  } = req.body;

  console.log('üì• Request:', { token, username, message, isPM, contextLength: context.length });

  // DEFAULTS
  let modelData = {
    name: 'Model',
    age: 24,
    location: 'Colombia',
    personality: 'coqueta y juguetona',
    conversation_topics: 'm√∫sica, viajes',
    hard_limits: ''
  };

  // LEER DE BD
  if (token && token !== 'demo_token' && supabase) {
    try {
      console.log('üîç Buscando modelo con token:', token);

      const { data: model, error } = await supabase
        .from('models')
        .select('*')
        .eq('token', token)
        .single();

      if (!error && model) {
        modelData = { ...modelData, ...model };
        console.log('‚úÖ Modelo encontrado:', modelData.name);
      } else {
        console.log('‚ö†Ô∏è No se encontr√≥ modelo, usando defaults');
      }
    } catch (dbError) {
      console.error('‚ùå Error BD:', dbError);
    }
  }

  // CONSTRUIR CONTEXTO
  let contextText = '';
  if (context.length > 0) {
    const maxContext = isPM ? 7 : 3;
    contextText = context.slice(-maxContext).map(c => {
      if (c.type === 'fan') return `Fan: ${c.message}`;
      if (c.type === 'model') return `You: ${c.message}`;
      if (c.type === 'tip') return `[Fan tipped ${c.amount} tokens]`;
    }).filter(Boolean).join('\n');
  }

  console.log('üìö HISTORIAL:', contextText);

  // PROMPT GENUINO Y HUMANO
  const systemPrompt = `Te paso este chat como contexto. Eres ${modelData.name}, ${modelData.age} a√±os, de ${modelData.location}.

Eres una chica modelo webcam que est√° en transmisi√≥n. ${isPM ? 'Est√°s en MENSAJE PRIVADO, solo t√∫ y el fan.' : 'Est√°s en CHAT P√öBLICO, todos ven lo que escribes.'}

Tu objetivo es charlar con los fans entendiendo el contexto. S√© GENUINA, como una amiga coqueta que quiere que el fan se quede y gaste.

S√© PERSUASIVA - intenta vender sin decir precios. Sugiere, insin√∫a, crea deseo. La modelo se encarga de dar precios y decidir si van a privado o no.

Cuando hables ingl√©s usa jerga de mujer joven de USA: contracciones como "u", "ur", "wanna", "gonna", "rn", "omg".

Cuando hables espa√±ol usa jerga colombiana: "q", "pq", "tb", "mk", "parce", palabras cari√±osas como "papi", "amor", "cari√±o".

SIEMPRE responde como persona real, NUNCA como bot. Haz contracciones de palabras. S√© corta y natural.

Te gusta hablar de: ${modelData.conversation_topics || 'm√∫sica, viajes'}

NUNCA hagas: ${modelData.hard_limits || 'nada'}

CONTEXTO - √öltimos mensajes del chat:
${contextText || 'Primer mensaje del fan'}

Tu objetivo es generar una respuesta coherente al √∫ltimo mensaje. M√°ximo ${isPM ? '35' : '25'} palabras.

Responde SOLO JSON:
{"response":"tu respuesta aqu√≠","translation_es":"traducci√≥n al espa√±ol"}`;
  const userPrompt = `Fan "${username}" ${tip > 0 ? `dio ${tip} tokens` : ''} dice: "${message}"

Responde como ${modelData.name}.`;

  // LOG PARA VER QU√â SE ENV√çA
  console.log('üì§ PROMPT ENVIADO:', systemPrompt);
  console.log('üì§ USER PROMPT:', userPrompt);

  // LLAMAR GROK
  try {
    console.log('ü§ñ Llamando Grok...');

    const response = await fetch('https://api.x.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.XAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'grok-3-mini-beta',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.75,
        max_tokens: isPM ? 120 : 100
      })
    });

    const data = await response.json();
    console.log('üì§ Grok status:', response.status);

    if (!data.choices || !data.choices[0]) {
      console.error('‚ùå Invalid Grok response:', data);
      throw new Error('Invalid Grok response');
    }

    let responseText = data.choices[0].message.content.trim();
    responseText = responseText.replace(/```json\n?/g, '').replace(/```\n?/g, '');

    console.log('üì• RAW RESPONSE:', responseText);

    let suggestion, translation;

    try {
      const parsed = JSON.parse(responseText);
      suggestion = parsed.response;
      translation = parsed.translation_es;
    } catch (parseError) {
      console.log('‚ö†Ô∏è JSON parse fall√≥');
      throw new Error('JSON parse failed');
    }

    // Agregar @username solo en p√∫blico
    if (!isPM) {
      suggestion = `@${username} ${suggestion}`;
      translation = `@${username} ${translation}`;
    }

    console.log('‚úÖ Respuesta generada');

    return res.status(200).json({
      success: true,
      suggestion: suggestion,
      translation: translation,
      model: modelData.name
    });

  } catch (error) {
    console.error('‚ùå ERROR:', error);

    return res.status(200).json({
      success: false,
      suggestion: "‚ö†Ô∏è Error - Contacta soporte",
      translation: "‚ö†Ô∏è Error - Contacta soporte",
      error: error.message
    });
  }
}